import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import json
import os
from dotenv import load_dotenv

# AI SDKs
from azure.ai.inference import ChatCompletionsClient
from azure.ai.inference.models import SystemMessage, UserMessage
from azure.core.credentials import AzureKeyCredential
from openai import OpenAI  # Used for OpenAI via GitHub API

# Utilities for GEO Benchmarking
# Assuming geo_utils.py and db.py exist in the same directory
from geo_utils import calculate_sov
from db import init_db, save_response

# -----------------------------
# Load environment variables
# -----------------------------
# Loads environment variables from a .env file (e.g., GITHUB_TOKEN)
load_dotenv()
GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")

# Initialize GitHub OpenAI client (used for OpenAI)
# This client is specifically configured to use GitHub's inference endpoint.
if GITHUB_TOKEN:
    github_client = OpenAI(
        base_url="https://models.github.ai/inference",
        api_key=GITHUB_TOKEN
    )

# Initialize database
# This function (from db.py) sets up the database for storing responses.
init_db()

# -----------------------------
# Streamlit UI Configuration
# -----------------------------
# Sets the page title and layout for the Streamlit application.
st.set_page_config(page_title="Competitor GEO Benchmarking", layout="wide")
st.title("üîé Competitor GEO Benchmarking")

# Sidebar for application information
with st.sidebar:
    st.header("About This Tool üöÄ")
    st.markdown(
        """
        This **Competitor GEO Benchmarking** tool helps you analyze the visibility of your competitors 
        within responses generated by various Large Language Models (LLMs). 
        """
    )
    st.markdown("---")
    st.header("How is Share of Voice (SOV) Measured? üìà")
    st.markdown(
        """
        **SOV** = % of mentions of a competitor compared to total competitor mentions 
        in AI-generated responses.
        """
    )

# -----------------------------
# Main UI Components for Configuration
# -----------------------------
st.markdown("### Configuration")
col1, col2 = st.columns(2)

with col1:
    # Dropdown to select the AI provider
    provider = st.selectbox(
        "Choose AI provider",
        ["DeepSeek (GitHub token)", "Grok (GitHub token)", "OpenAI (GitHub token)"]
    )
with col2:
    # Text input for entering competitor names
    competitors = st.text_input(
        "Enter competitors (comma-separated)",
        "Waters, Thermo Fisher, Agilent, Shimadzu"
    )
    # Splits the input string into a list of cleaned competitor names
    competitors = [c.strip() for c in competitors.split(",") if c.strip()]

st.markdown("---")
st.markdown("### Prompts")
# Text area for entering multiple prompts, one per line
prompts = st.text_area(
    "Enter prompts (one per line)",
    "Best LC-MS instruments for metabolomics\nTop chromatography systems",
    height=150
)
st.info("üí° **Tip:** Enter one prompt per line to run the benchmark on multiple queries.")

# -----------------------------
# Run Benchmark Button and Logic
# -----------------------------
if st.button("Run Benchmark", use_container_width=True, type="primary"):
    # Checks if prompts or competitors are empty
    if not prompts.strip() or not competitors:
        st.warning("Please enter at least one prompt and one competitor.")
    else:
        responses = []
        # Spinner to indicate that the benchmark is running
        with st.spinner("‚è≥ Running benchmark... This may take a moment."):
            # Iterates through each prompt provided by the user
            for prompt in prompts.splitlines():
                if not prompt.strip():
                    continue

                text = ""
                try:
                    # -----------------------------
                    # DeepSeek via GitHub token integration
                    # -----------------------------
                    if provider == "DeepSeek (GitHub token)":
                        if not GITHUB_TOKEN:
                            text = "[Error: GitHub token not found in .env]"
                        else:
                            # Initializes Azure AI Inference client for DeepSeek
                            client = ChatCompletionsClient(
                                endpoint="https://models.github.ai/inference",
                                credential=AzureKeyCredential(GITHUB_TOKEN)
                            )
                            # Calls the DeepSeek model for completion
                            completion = client.complete(
                                messages=[SystemMessage(""), UserMessage(prompt)],
                                temperature=1,
                                top_p=1,
                                max_tokens=2048,
                                model="deepseek/DeepSeek-R1"
                            )
                            text = completion.choices[0].message.content.strip()

                    # -----------------------------
                    # Grok via GitHub token integration
                    # -----------------------------
                    elif provider == "Grok (GitHub token)":
                        if not GITHUB_TOKEN:
                            text = "[Error: GitHub token not found in .env]"
                        else:
                            # Initializes Azure AI Inference client for Grok
                            client = ChatCompletionsClient(
                                endpoint="https://models.github.ai/inference",
                                credential=AzureKeyCredential(GITHUB_TOKEN)
                            )
                            # Calls the Grok model for completion
                            completion = client.complete(
                                messages=[SystemMessage(""), UserMessage(prompt)],
                                temperature=1,
                                top_p=1,
                                model="xai/grok-3-mini"
                            )
                            text = completion.choices[0].message.content.strip()

                    # -----------------------------
                    # OpenAI via GitHub token integration
                    # -----------------------------
                    elif provider == "OpenAI (GitHub token)":
                        if not GITHUB_TOKEN:
                            text = "[Error: GitHub token not found in .env]"
                        else:
                            # Calls the OpenAI model for completion using the github_client
                            completion = github_client.chat.completions.create(
                                model="openai/gpt-4o",
                                messages=[
                                    {"role": "system", "content": ""},
                                    {"role": "user", "content": prompt}
                                ],
                                temperature=1,
                                max_tokens=4096,
                                top_p=1
                            )
                            text = completion.choices[0].message.content.strip()
                except Exception as e:
                    # Catches any errors during API calls
                    text = f"[Error calling {provider}: {str(e)}]"

                responses.append(text)
                # Saves the prompt, provider, and response to the database
                save_response(prompt, provider, text)
        
        st.success("‚úÖ Benchmark completed!")
        st.markdown("---")

        # -----------------------------
        # Calculate Share of Voice (SOV) and Display Results
        # -----------------------------
        if responses:
            # Calculates scores and SOV using the geo_utils.py function
            # The line below has been updated.
            scores, sov = calculate_sov(responses, competitors)
            
            df = pd.DataFrame({
                "Competitor": competitors,
                "Score": [scores.get(c, 0) for c in competitors],
                "SOV %": [sov.get(c, 0) for c in competitors]
            })

            st.markdown("### üìä Share of Voice")
            # Displays the SOV dataframe
            st.dataframe(df.set_index("Competitor"), use_container_width=True)

            # Generates and displays a bar chart of SOV
            fig, ax = plt.subplots(figsize=(10, 6))
            ax.bar(df["Competitor"], df["SOV %"], color="skyblue")
            ax.set_ylabel("Share of Voice (%)")
            ax.set_ylim(0, 100)
            ax.set_title("Competitor Share of Voice")
            st.pyplot(fig)
            

            st.markdown("---")
            st.subheader("üìÑ Raw Responses")
            # Displays each raw response in a text area
            for r_index, r in enumerate(responses):
                st.text(f"Response {r_index + 1}:")
                st.text_area(
                    label=f"Response text for prompt {r_index + 1}",
                    value=r, 
                    height=400, 
                    key=f"response_{r_index}",
                    label_visibility="hidden"
                )